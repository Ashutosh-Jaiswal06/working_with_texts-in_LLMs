# working-with-texts-in-LLMs
This is the basic code to convert raw text data into tokens for training purposes. I started with an outdated method and then progress toward modern tokenization known as #Byte Pair Enoding. This encoding method is also used in GPT-2 and GPT-3 architectures.
